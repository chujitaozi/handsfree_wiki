在[视觉实验](/docs/Tutorial/2.3-Vision-Test.md)演示了如何控制机器人跟踪二维码，本章将讲解如何控制机器人的头部Xtion跟踪二维码。HandFree机器人的头部是由二自由度云台构成，Xtion置于云台上，可以进行俯仰和偏转运动。  
云台由两个模拟舵机组成，确保舵机已正确连接至主控。实现头部跟踪的过程与7.4章节的过程类似。  
建议节点都在工控机上运行

### 第一步 ###  
打开机器人抽象节点
>sudo service robot restart
确保XBOX可以正常遥控机器人,如果不能,请参考[常见问题及解答](https://github.com/HANDS-FREE/HANDS-FREE.github.io/wiki/7.1-Teleop)进行解决。    

### 第二步 ###
>roslaunch handsfree_bringup xtion.launch  

打开Xtion驱动节点，将发布一系列RGB图像数据和深度图像数据。

### 第三步 ###  
使用RGB图像数据进行二维码识别：
>roslaunch handsfree_ar_tags ar_indiv_rgb_camera.launch  

或者使用深度图像数据进行二维码识别：
>roslaunch handsfree_ar_tags ar_indiv_depth_camera.launch  

上面两条命令二选一即可，它们都是使用开源的二维码识别库进行二维码的识别，`ar_indiv_rgb_camera.launch`和`ar_indiv_depth_camera.launch`的区别主要是订阅的话题不同，更多资料请参考[ar_track_alvar](http://wiki.ros.org/ar_track_alvar/)的WIKI。  
### 第四步 ###  
>rosrun handsfree_ar_tags head_tracker.py

运行头部跟踪器，其将根据二维码的识别结果控制机器人的云台进行运动。  
将`/handsfree/handsfree_ar_tags/config/Markers_0_2.png`文件打印在纸上，将打印出的图案放置在Xtion摄像头前方，慢慢移动图案，机器人的头部将跟随二维码图案位置的移动而运动。  
