在[7.3 RGBD Test](https://github.com/HANDS-FREE/HANDS-FREE.github.io/wiki/7.3-RGBD-Test)章节我们使用Xtion模拟激光雷达进行建图，在本章节将讲解使用Xtion和计算机视觉方法实现机器人跟踪二维码。  
### 第一步 ###  
>roslaunch handsfree_hw handsfree_hw.launch  

打开机器人抽象节点，确保没有出现`timeout`的问题，如果出现该问题请参考[7.1 Teleop](https://github.com/HANDS-FREE/HANDS-FREE.github.io/wiki/7.1-Teleop)章节进行解决。  

### 第二步 ###
>roslaunch handsfree_bringup xtion.launch  

打开Xtion驱动节点，将发布一系列RGB图像数据和深度图像数据。

### 第三步 ###  
使用RGB图像数据进行二维码识别：
>roslaunch handsfree_ar_tags ar_indiv_rgb_camera.launch  

![picture](https://github.com/doctorsrn/git_test/blob/master/HandsFree_ROS/7/7.4/4_indiv_rgb.png?raw=true)  
或者使用深度图像数据进行二维码识别：
>roslaunch handsfree_ar_tags ar_indiv_depth_camera.launch  

上面两条命令二选一即可，它们都是使用开源的二维码识别库**ar_track_alvar**进行二维码的识别，`ar_indiv_rgb_camera.launch`和`ar_indiv_depth_camera.launch`文件的主要区别是订阅的话题不同，更多资料请参考[ar_track_alvar](http://wiki.ros.org/ar_track_alvar/)的WIKI。  
### 第四步 ###  
>roslaunch handsfree_ar_tags ar_follower.launch  

![picture](https://github.com/doctorsrn/git_test/blob/master/HandsFree_ROS/7/7.4/4_follower.png?raw=true)
![picture](https://github.com/doctorsrn/git_test/blob/master/HandsFree_ROS/7/7.4/4_ar_display.png?raw=true)  
运行二维码跟踪器，其将根据二维码的识别结果控制机器人进行移动。  
将`/handsfree/handsfree_ar_tags/config/Markers_0_2.png`文件打印在纸上，将打印出的图案放置在Xtion摄像头前方，慢慢移动图案，机器人将跟随二维码图案位置的移动而运动。
